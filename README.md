<h1 align = "center">问泉 AI</h1>

### 一、项目简介

#### 1. 项目背景
传统学习方法在即时反馈、互动性和个性化概念检验方面存在局限，难以确保学习者对知识点的深度理解和牢固掌握。

#### 2. 项目概述
“问泉 (Inquiry Spring)” 是一款由先进大语言模型 (LLM) 驱动的互动式概念学习增强工具。它通过动态生成与学习内容紧密相关的测验题目，并为错误答案提供智能化、上下文感知的深度解释，赋能用户进行主动探索式学习，显著提升概念理解的效率和深度。

#### 3. 核心功能

- **学习内容输入：** 用户通过 Django 表单提交文本段落作为学习材料。
- **测验生成模块 (集成于 Django 视图)：**
    - Django 视图接收学习材料，调用 LLM API 或本地模型。
    - 根据输入文本，生成指定数量的选择题和/或判断题。
    - 确保题目与原文内容紧密相关。
    - 生成的题目、选项、正确答案以结构化格式 (如 JSON) 存储于 Django 模型定义的数据库中。
- **互动答题界面 (通过 Django 模板渲染)：**
    - Django 视图从数据库获取题目，并通过模板逐一展示。
    - 用户在前端选择答案并通过表单提交。
- **反馈与解释模块 (Django 视图处理)：**
    - 后端视图判断答案对错。
    - 若答错，提供“请求 AI 解释”功能。
    - 点击后，Django 视图调用 LLM，结合原文、问题、用户错误答案和正确答案，生成解释性文本。
    - 将解释通过模板清晰地展示给用户。
- **数据持久化：** 使用 Django ORM 将学习材料、生成的测验、用户答案（可选）等信息存储到数据库（如 SQLite）。
- **基础用户提示与引导：** 在 Django 模板中提供必要的操作说明或状态提示。

#### 4. 项目亮点与创新性

- **动态内容适应：** 非固定题库，AI 可根据任意（适宜长度和格式的）文本生成测验，灵活性强。
- **深度反馈机制：** 区别于简单告知对错，提供基于原文的、个性化的“为什么”解释，直击理解痛点。
- **LLM 教育场景应用探索：** 将强大的生成式 AI 能力应用于教育辅助，探索提升学习体验的新范式。
- **稳健的 Web 应用框架：** 采用 Django 构建，提供更结构化、可扩展和可维护的后端支持。
- **优化的交互体验：** 通过 Django 模板和可能的少量前端技术，确保界面简洁、操作流畅、反馈及时。
- **增强的健壮性：** 利用 Django 框架的特性及通过测试和错误处理，提高应用在常见场景下的稳定性。

#### 5. 技术架构与选型

- 编程语言： Python 3.10+
- Web 框架： Django 用于构建后端逻辑、数据模型、视图和用户界面。
    - **模型 (Models)：** 定义数据结构，如学习材料、测验题目等。
    - **视图 (Views)：** 处理用户请求，集成 AI 逻辑，与模型和模板交互。
    - **模板 (Templates)：** 使用 Django 模板语言渲染 HTML 页面，展示内容给用户。
    - **表单 (Forms)：** 处理用户输入和数据验证。
- 数据库： SQLite (初期) 或其他 Django 支持的数据库。
- LLM 交互/编排： LangChain 用于管理 Prompt、与 LLM 交互、构建应用逻辑链。
- LLM 模型： [待定] 提供核心的文本理解、题目生成和解释能力。
- 核心原则： 保持核心 AI 逻辑（使用 LangChain 等）与 Django 的视图和模型清晰分离，便于维护和扩展。
- 核心原则： 强调模块化设计，利用 Django 的 App 结构组织代码。

---

### 二、项目企划书

#### 1. 项目综述
*   **项目名称：** 问泉 (Inquiry Spring)
*   **团队名称：** Vertor Three
*   **项目定位：** AI 驱动的互动式概念学习工具，通过动态测验与智能解释提升理解效率和深度。
*   **问题陈述：** 传统学习缺乏即时反馈、个性化检验和深度解惑机制。
*   **解决方案：** 利用 LLM 技术，实现基于学习内容的动态测验生成和针对性错误解释，构建高效学习闭环。
*   **项目目标**
    * 开发一个**稳定、健壮、用户体验良好**的 Web 应用原型 (MVP)。
    * 实现高质量、相关的动态测验题目生成功能（选择题/判断题）。
    * 实现清晰、准确、有帮助的 AI 错误解释功能。
    * 优化核心 Prompt Engineering，提升 AI 生成内容的质量和稳定性。
    * 进行较为全面的测试，提升应用的可靠性。
    * 完成清晰的项目文档和精炼的演示材料。

#### 2. 目标用户与价值
*   **目标用户：** 需要高效学习、深入理解特定领域知识概念的学生、自学者及职业人士。
*   **用户价值：**
    - 提高学习效率：通过即时自测快速定位理解盲区。
    - 加深概念理解：AI 的深度解释帮助用户突破难点。
    - 增强学习主动性：互动形式激发学习兴趣和参与感。
    - 个性化学习体验：可根据自己的学习材料生成专属测验。


#### 3. 核心功能

- **学习内容输入：** 用户通过 Django 表单提交文本段落作为学习材料。
- **测验生成模块 (集成于 Django 视图)：**
    - Django 视图接收学习材料，调用 LLM API 或本地模型。
    - 根据输入文本，生成指定数量的选择题和/或判断题。
    - 确保题目与原文内容紧密相关。
    - 生成的题目、选项、正确答案以结构化格式 (如 JSON) 存储于 Django 模型定义的数据库中。
- **互动答题界面 (通过 Django 模板渲染)：**
    - Django 视图从数据库获取题目，并通过模板逐一展示。
    - 用户在前端选择答案并通过表单提交。
- **反馈与解释模块 (Django 视图处理)：**
    - 后端视图判断答案对错。
    - 若答错，提供“请求 AI 解释”功能。
    - 点击后，Django 视图调用 LLM，结合原文、问题、用户错误答案和正确答案，生成解释性文本。
    - 将解释通过模板清晰地展示给用户。
- **数据持久化：** 使用 Django ORM 将学习材料、生成的测验、用户答案（可选）等信息存储到数据库（如 SQLite）。
- **基础用户提示与引导：** 在 Django 模板中提供必要的操作说明或状态提示。

#### 4. 项目亮点与创新性

- **动态内容适应：** 非固定题库，AI 可根据任意（适宜长度和格式的）文本生成测验，灵活性强。
- **深度反馈机制：** 区别于简单告知对错，提供基于原文的、个性化的“为什么”解释，直击理解痛点。
- **LLM 教育场景应用探索：** 将强大的生成式 AI 能力应用于教育辅助，探索提升学习体验的新范式。
- **稳健的 Web 应用框架：** 采用 Django 构建，提供更结构化、可扩展和可维护的后端支持。
- **优化的交互体验：** 通过 Django 模板和可能的少量前端技术，确保界面简洁、操作流畅、反馈及时。
- **增强的健壮性：** 利用 Django 框架的特性及通过测试和错误处理，提高应用在常见场景下的稳定性。

#### 5. 技术架构与选型

- 编程语言： Python 3.10+
- Web 框架： Django 用于构建后端逻辑、数据模型、视图和用户界面。
    - **模型 (Models)：** 定义数据结构，如学习材料、测验题目等。
    - **视图 (Views)：** 处理用户请求，集成 AI 逻辑，与模型和模板交互。
    - **模板 (Templates)：** 使用 Django 模板语言渲染 HTML 页面，展示内容给用户。
    - **表单 (Forms)：** 处理用户输入和数据验证。
- 数据库： SQLite (初期) 或其他 Django 支持的数据库。
- LLM 交互/编排： LangChain 用于管理 Prompt、与 LLM 交互、构建应用逻辑链。
- LLM 模型： [待定] 提供核心的文本理解、题目生成和解释能力。
- 核心原则： 保持核心 AI 逻辑（使用 LangChain 等）与 Django 的视图和模型清晰分离，便于维护和扩展。
- 核心原则： 强调模块化设计，利用 Django 的 App 结构组织代码。


#### 6. 团队分工
*   **成员 A (LLM & Prompt Engineer):** 投入更多时间进行 Prompt 迭代、效果评估与优化。
*   **成员 B (后端 & 逻辑):** 确保逻辑健壮性，优化代码结构，配合 Prompt 优化调整接口。
*   **成员 C (前端 & 集成):** 负责 UI/UX 的细节打磨，确保交互流畅，集成更稳定，并负责最终文档和演示的高质量呈现。

#### 7. 评估指标

* 功能完整性与流畅度。
* AI 生成内容的**质量**（相关性、准确性、帮助性 - 通过典型案例展示）。
* 用户体验与界面设计的**友好度**。
* 应用的**稳定性**和基础错误处理能力。
* 演示的清晰度和说服力。

#### 8. 风险与应对
* **风险 1：LLM 生成质量不稳定**
    * 应对：利用充足时间进行深度 Prompt Engineering 和测试；明确告知用户 AI 的局限性。
* **风险 2：范围蔓延 (Scope Creep)**
    * 应对：严格遵守 MVP 原则，抵制增加不必要功能的诱惑，将时间聚焦于核心功能的质量提升。
* **风险 3：API 成本或本地部署资源限制。**
    * 应对：优先选择有免费额度的 API；若本地部署，选用量化后的小模型；比赛期间控制调用频率。

#### 9. 未来展望
* **功能扩展：** 支持更多题目类型（填空、简答），支持图片、公式等更复杂的输入，引入用户反馈机制优化模型。
* **个性化增强：** 增加用户画像、学习进度跟踪、自适应难度调整等功能（Django 的用户模型和数据库能力为此提供基础）。
* **技术升级：** **当前项目正基于 Django 进行构建和深化**，以支持更复杂的功能和未来可能的用户管理。
* **领域拓展**： 应用于更多专业领域或特定教学场景。